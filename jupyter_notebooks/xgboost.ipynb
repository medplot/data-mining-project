{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing.preprocessing_label_encoding import  get_preprocessed_brfss_dataset_label_encoded_train_test_split, get_preprocessed_brfss_dataset_label_encoded_train_test_split_undersampled, get_preprocessed_brfss_dataset_label_encoded_train_test_split_oversampled\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, fbeta_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "        GenHealth  PhysHealth  MentHealth  Healthcare  MedCost  Checkup  \\\n241445        3.0         0.0         0.0         1.0      2.0      1.0   \n107433        3.0         0.0         0.0         1.0      2.0      1.0   \n255533        2.0         0.0         0.0         1.0      1.0      1.0   \n31855         1.0         0.0         0.0         1.0      2.0      1.0   \n76133         2.0         0.0         0.0         1.0      2.0      1.0   \n93828         2.0         0.0         0.0         1.0      2.0      1.0   \n71236         2.0         0.0         0.0         1.0      2.0      2.0   \n212026        3.0         0.1         0.0         1.0      2.0      1.0   \n169431        3.0         1.0         0.0         1.0      2.0      1.0   \n60906         1.0         0.0         0.0         1.0      2.0      2.0   \n\n        HighBP  HighChol  HeartAttack  AngiCoro  ...    Height    Weight  BMI  \\\n241445     1.0       2.0          2.0       2.0  ...  0.855895  0.469484  4.0   \n107433     1.0       2.0          2.0       2.0  ...  0.764192  0.392789  4.0   \n255533     1.0       2.0          2.0       2.0  ...  0.855895  0.445989  4.0   \n31855      3.0       2.0          2.0       2.0  ...  0.685590  0.203450  2.0   \n76133      1.0       1.0          2.0       2.0  ...  0.698690  0.219079  2.0   \n93828      1.0       1.0          2.0       2.0  ...  0.799127  0.289495  3.0   \n71236      3.0       2.0          2.0       2.0  ...  0.742358  0.258203  3.0   \n212026     3.0       2.0          2.0       2.0  ...  0.698690  0.234742  3.0   \n169431     1.0       2.0          2.0       2.0  ...  0.777293  0.336450  4.0   \n60906      3.0       2.0          2.0       2.0  ...  0.711790  0.211247  2.0   \n\n        Education  Alcohol  Smoking  FruitCons  VegetCons  PhysActivity  \\\n241445        3.0      1.0      3.0        2.0        1.0           3.0   \n107433        3.0      1.0      4.0        2.0        1.0           4.0   \n255533        3.0      1.0      4.0        1.0        2.0           3.0   \n31855         4.0      1.0      4.0        1.0        1.0           3.0   \n76133         4.0      1.0      4.0        1.0        1.0           1.0   \n93828         3.0      1.0      2.0        2.0        1.0           1.0   \n71236         2.0      1.0      4.0        2.0        1.0           1.0   \n212026        3.0      1.0      1.0        2.0        1.0           2.0   \n169431        4.0      1.0      3.0        2.0        2.0           3.0   \n60906         3.0      1.0      3.0        1.0        1.0           1.0   \n\n        Muscles  \n241445      2.0  \n107433      2.0  \n255533      1.0  \n31855       1.0  \n76133       1.0  \n93828       2.0  \n71236       2.0  \n212026      1.0  \n169431      2.0  \n60906       2.0  \n\n[10 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GenHealth</th>\n      <th>PhysHealth</th>\n      <th>MentHealth</th>\n      <th>Healthcare</th>\n      <th>MedCost</th>\n      <th>Checkup</th>\n      <th>HighBP</th>\n      <th>HighChol</th>\n      <th>HeartAttack</th>\n      <th>AngiCoro</th>\n      <th>...</th>\n      <th>Height</th>\n      <th>Weight</th>\n      <th>BMI</th>\n      <th>Education</th>\n      <th>Alcohol</th>\n      <th>Smoking</th>\n      <th>FruitCons</th>\n      <th>VegetCons</th>\n      <th>PhysActivity</th>\n      <th>Muscles</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>241445</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.855895</td>\n      <td>0.469484</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>107433</th>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.764192</td>\n      <td>0.392789</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>255533</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.855895</td>\n      <td>0.445989</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>31855</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.685590</td>\n      <td>0.203450</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>76133</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.698690</td>\n      <td>0.219079</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>93828</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.799127</td>\n      <td>0.289495</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>71236</th>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.742358</td>\n      <td>0.258203</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>212026</th>\n      <td>3.0</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.698690</td>\n      <td>0.234742</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>169431</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.777293</td>\n      <td>0.336450</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>60906</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>...</td>\n      <td>0.711790</td>\n      <td>0.211247</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 28 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_validation, data_test, target_train, target_validation, target_test = get_preprocessed_brfss_dataset_label_encoded_train_test_split(include_test_data=True)\n",
    "data_train.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "sample_weights = compute_sample_weight(class_weight='balanced',y=target_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def validate_xgboost_classifier(estimator: XGBClassifier):\n",
    "    estimator.fit(data_train, target_train, sample_weight=sample_weights)\n",
    "    predictions = estimator.predict(data_validation)\n",
    "    return accuracy_score(target_validation, predictions), fbeta_score(target_validation, predictions, beta=2), precision_score(target_validation, predictions), recall_score(target_validation, predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_child_weight_parameter 1 --> Accuracy: 0.7507549650051515, F-Score: 0.6048936170212765, Precision: 0.3123489343001538, Recall: 0.7898319211001528\n",
      "Min_child_weight_parameter 2 --> Accuracy: 0.7503286318257718, F-Score: 0.6026481607629427, Precision: 0.31144114411441143, Recall: 0.7864981247395472\n",
      "Min_child_weight_parameter 3 --> Accuracy: 0.7499022986463921, F-Score: 0.6016133838491337, Precision: 0.3108435059936215, Recall: 0.78524795110432\n",
      "Min_child_weight_parameter 4 --> Accuracy: 0.7495114932319608, F-Score: 0.6045578115708097, Precision: 0.3112970253718285, Recall: 0.7908042783719961\n",
      "Min_child_weight_parameter 5 --> Accuracy: 0.749653604291754, F-Score: 0.6040161495962602, Precision: 0.31126806833114323, Recall: 0.789693012918461\n",
      "Min_child_weight_parameter 6 --> Accuracy: 0.7487831740505205, F-Score: 0.6029852013843181, Precision: 0.3103316396219199, Recall: 0.7889984720100014\n",
      "Min_child_weight_parameter 7 --> Accuracy: 0.7474686467474331, F-Score: 0.6045305387953848, Precision: 0.3097239546613157, Recall: 0.7933046256424503\n",
      "Min_child_weight_parameter 8 --> Accuracy: 0.7490141045226845, F-Score: 0.6042789828925583, Precision: 0.3108417949557812, Recall: 0.790943186553688\n",
      "Min_child_weight_parameter 9 --> Accuracy: 0.7494404377020641, F-Score: 0.6056329060191866, Precision: 0.3115174672489083, Recall: 0.7927489929156827\n",
      "Min_child_weight_parameter 10 --> Accuracy: 0.748605535225779, F-Score: 0.6059931760866341, Precision: 0.3109673209722147, Recall: 0.7944158910959855\n",
      "Min_child_weight_parameter 11 --> Accuracy: 0.7488542295804171, F-Score: 0.6048874652637831, Precision: 0.310874897792314, Recall: 0.7921933601889152\n",
      "Min_child_weight_parameter 12 --> Accuracy: 0.7479837993391836, F-Score: 0.6077079279126828, Precision: 0.31093073593073595, Recall: 0.7981664120016669\n",
      "Min_child_weight_parameter 13 --> Accuracy: 0.7488542295804171, F-Score: 0.6053697537802472, Precision: 0.3109985291714332, Recall: 0.7930268092790665\n",
      "Min_child_weight_parameter 14 --> Accuracy: 0.7479482715742353, F-Score: 0.6047960005084099, Precision: 0.3101575230852797, Recall: 0.7931657174607585\n",
      "Min_child_weight_parameter 15 --> Accuracy: 0.7478772160443387, F-Score: 0.6047447574666384, Precision: 0.3100901487998262, Recall: 0.7931657174607585\n",
      "Min_child_weight_parameter 16 --> Accuracy: 0.7470067858031051, F-Score: 0.604278188011764, Precision: 0.30930849623653, Recall: 0.7934435338241422\n",
      "Min_child_weight_parameter 17 --> Accuracy: 0.7470956052154759, F-Score: 0.6038606442873471, Precision: 0.3092682926829268, Recall: 0.7926100847339909\n",
      "Min_child_weight_parameter 18 --> Accuracy: 0.7481969659288734, F-Score: 0.6065001058649164, Precision: 0.31078442009330587, Recall: 0.7958049729129045\n",
      "Min_child_weight_parameter 19 --> Accuracy: 0.7460830639144491, F-Score: 0.6044954264106301, Precision: 0.3086672779245995, Recall: 0.7949715238227532\n"
     ]
    }
   ],
   "source": [
    "min_child_weight_parameters = range(1, 20)\n",
    "for param in min_child_weight_parameters:\n",
    "    estimator = XGBClassifier(min_child_weight=param)\n",
    "    accuracy, f_score, precision, recall = validate_xgboost_classifier(estimator)\n",
    "    print(f\"Min_child_weight_parameter {param} --> Accuracy: {accuracy}, F-Score: {f_score}, Precision: {precision}, Recall: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample 0.1 --> Accuracy: 0.7345543041887235, F-Score: 0.5770849997895003, Precision: 0.2930518439337253, Recall: 0.7616335602166968\n",
      "Subsample 0.15000000000000002 --> Accuracy: 0.7396347745763314, F-Score: 0.5885950482938967, Precision: 0.29975298034582754, Recall: 0.775385470204195\n",
      "Subsample 0.20000000000000004 --> Accuracy: 0.7409137741144705, F-Score: 0.5915056122879567, Precision: 0.3014516129032258, Recall: 0.7788581747464925\n",
      "Subsample 0.25000000000000006 --> Accuracy: 0.7429033289515756, F-Score: 0.5949211982929818, Precision: 0.3038083935699644, Recall: 0.7823308792887901\n",
      "Subsample 0.30000000000000004 --> Accuracy: 0.742370412477351, F-Score: 0.5975167587166407, Precision: 0.3040982727175196, Recall: 0.7874704820113905\n",
      "Subsample 0.3500000000000001 --> Accuracy: 0.7440579813123956, F-Score: 0.5953363380520112, Precision: 0.3047717055733088, Recall: 0.7816363383803306\n",
      "Subsample 0.40000000000000013 --> Accuracy: 0.7424414680072476, F-Score: 0.5994102780117946, Precision: 0.30464568614857634, Recall: 0.7906653701903043\n",
      "Subsample 0.45000000000000007 --> Accuracy: 0.744111272959818, F-Score: 0.6005993331363694, Precision: 0.30618612157073694, Recall: 0.7906653701903043\n",
      "Subsample 0.5000000000000001 --> Accuracy: 0.7425835790670409, F-Score: 0.5970259438936933, Precision: 0.30412592672182226, Recall: 0.7863592165578552\n",
      "Subsample 0.5500000000000002 --> Accuracy: 0.7445731339041461, F-Score: 0.5969912403199187, Precision: 0.30558864940972597, Recall: 0.783858869287401\n",
      "Subsample 0.6000000000000002 --> Accuracy: 0.7458166056773369, F-Score: 0.6012564514764362, Precision: 0.30762987012987014, Recall: 0.789693012918461\n",
      "Subsample 0.6500000000000001 --> Accuracy: 0.7470778413330017, F-Score: 0.6024019825888035, Precision: 0.30887863155036654, Recall: 0.7901097374635366\n",
      "Subsample 0.7000000000000002 --> Accuracy: 0.7469712580381568, F-Score: 0.5995079220310944, Precision: 0.3080486077053022, Recall: 0.78524795110432\n",
      "Subsample 0.7500000000000002 --> Accuracy: 0.7471844246278466, F-Score: 0.601674260887994, Precision: 0.30877154820816793, Recall: 0.7887206556466176\n",
      "Subsample 0.8000000000000002 --> Accuracy: 0.7465804526237254, F-Score: 0.6029284187808128, Precision: 0.30863796371513674, Recall: 0.7916377274621476\n",
      "Subsample 0.8500000000000002 --> Accuracy: 0.7482324936938217, F-Score: 0.6024275346942239, Precision: 0.30976541189307144, Recall: 0.7887206556466176\n",
      "Subsample 0.9000000000000002 --> Accuracy: 0.7492983266422709, F-Score: 0.605449683799499, Precision: 0.31136090799956345, Recall: 0.7926100847339909\n",
      "Subsample 0.9500000000000003 --> Accuracy: 0.7479482715742353, F-Score: 0.6003694581280787, Precision: 0.30901639344262294, Recall: 0.7855257674677039\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "subsample_parameters = np.arange(0.1, 1, 0.05)\n",
    "for param in subsample_parameters:\n",
    "    estimator = XGBClassifier(min_child_weight=10, subsample=param)\n",
    "    accuracy, f_score, precision, recall = validate_xgboost_classifier(estimator)\n",
    "    print(f\"Subsample {param} --> Accuracy: {accuracy}, F-Score: {f_score}, Precision: {precision}, Recall: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling method uniform --> Accuracy: 0.748605535225779, F-Score: 0.6059931760866341, Precision: 0.3109673209722147, Recall: 0.7944158910959855\n",
      "Sampling method gradient_based --> Accuracy: 0.748605535225779, F-Score: 0.6059931760866341, Precision: 0.3109673209722147, Recall: 0.7944158910959855\n"
     ]
    }
   ],
   "source": [
    "sampling_method = [\"uniform\", \"gradient_based\"]\n",
    "for param in sampling_method:\n",
    "    estimator = XGBClassifier(min_child_weight=10, sampling_method=param,)\n",
    "    accuracy, f_score, precision, recall = validate_xgboost_classifier(estimator)\n",
    "    print(f\"Sampling method {param} --> Accuracy: {accuracy}, F-Score: {f_score}, Precision: {precision}, Recall: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate0.1 --> Accuracy: 0.7408427185845738, F-Score: 0.6108257110637765, Precision: 0.30644316396018856, Recall: 0.8126128628976247\n",
      "Learning rate0.15000000000000002 --> Accuracy: 0.7428500373041532, F-Score: 0.6106094571662023, Precision: 0.3078426194877211, Recall: 0.8096957910820948\n",
      "Learning rate0.20000000000000004 --> Accuracy: 0.7463672860340356, F-Score: 0.6111661015521345, Precision: 0.31059024990635203, Recall: 0.8062230865397972\n",
      "Learning rate0.25000000000000006 --> Accuracy: 0.7464738693288805, F-Score: 0.6057373413042101, Precision: 0.309281130345683, Recall: 0.796638422003056\n",
      "Learning rate0.30000000000000004 --> Accuracy: 0.748605535225779, F-Score: 0.6059931760866341, Precision: 0.3109673209722147, Recall: 0.7944158910959855\n",
      "Learning rate0.3500000000000001 --> Accuracy: 0.7509148399474189, F-Score: 0.6020205895517616, Precision: 0.3117377628166216, Recall: 0.7846923183775525\n",
      "Learning rate0.40000000000000013 --> Accuracy: 0.7504885067680392, F-Score: 0.5983909174331506, Precision: 0.310468914355312, Recall: 0.7789970829281845\n",
      "Learning rate0.45000000000000007 --> Accuracy: 0.7520517284257647, F-Score: 0.5940562214550679, Precision: 0.3105767613922986, Recall: 0.769690234754827\n",
      "Learning rate0.5000000000000001 --> Accuracy: 0.7519273812484457, F-Score: 0.5938853393936795, Precision: 0.3104337106354365, Recall: 0.7695513265731352\n",
      "Learning rate0.5500000000000002 --> Accuracy: 0.7527978114896792, F-Score: 0.5916428433248071, Precision: 0.3105432391267558, Recall: 0.7646895402139186\n",
      "Learning rate0.6000000000000002 --> Accuracy: 0.7540590471453441, F-Score: 0.5875242823224692, Precision: 0.31048249116003196, Recall: 0.7562161411307126\n",
      "Learning rate0.6500000000000001 --> Accuracy: 0.7541123387927665, F-Score: 0.5853305383268861, Precision: 0.30995022028952335, Recall: 0.7524656202250313\n",
      "Learning rate0.7000000000000002 --> Accuracy: 0.7548051302092585, F-Score: 0.5854101765316718, Precision: 0.3105347716318568, Recall: 0.7517710793165717\n",
      "Learning rate0.7500000000000002 --> Accuracy: 0.7553025189185348, F-Score: 0.581362551529616, Precision: 0.30987625766161675, Recall: 0.744408945686901\n",
      "Learning rate0.8000000000000002 --> Accuracy: 0.7549650051515259, F-Score: 0.574441228318353, Precision: 0.3077595755844459, Recall: 0.7332962911515488\n",
      "Learning rate0.8500000000000002 --> Accuracy: 0.7554623938608022, F-Score: 0.5743721548212846, Precision: 0.3081507449605609, Recall: 0.7326017502430893\n",
      "Learning rate0.9000000000000002 --> Accuracy: 0.7530642697267915, F-Score: 0.5689977805822708, Precision: 0.3047430369420813, Recall: 0.7264897902486457\n",
      "Learning rate0.9500000000000003 --> Accuracy: 0.754289977617508, F-Score: 0.5692643051771118, Precision: 0.3058141577375725, Recall: 0.7255174329768024\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.arange(0.1, 1, 0.05)\n",
    "for param in learning_rates:\n",
    "    estimator = XGBClassifier(min_child_weight=10, eta=param,)\n",
    "    accuracy, f_score, precision, recall = validate_xgboost_classifier(estimator)\n",
    "    print(f\"Learning rate {param} --> Accuracy: {accuracy}, F-Score: {f_score}, Precision: {precision}, Recall: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min split loss 0 --> Accuracy: 0.7463672860340356, F-Score: 0.6111661015521345, Precision: 0.31059024990635203, Recall: 0.8062230865397972\n",
      "Min split loss 1 --> Accuracy: 0.7454080363804313, F-Score: 0.6092786326225608, Precision: 0.30939019827908715, Recall: 0.8041394638144187\n",
      "Min split loss 2 --> Accuracy: 0.7444132589618787, F-Score: 0.6075267686223363, Precision: 0.3082012699429059, Recall: 0.8023336574524239\n",
      "Min split loss 3 --> Accuracy: 0.7438981063701282, F-Score: 0.6082699499936967, Precision: 0.3080114905841047, Recall: 0.8042783719961105\n",
      "Min split loss 4 --> Accuracy: 0.7446619533165169, F-Score: 0.6077853761178328, Precision: 0.308452133055689, Recall: 0.8024725656341158\n",
      "Min split loss 5 --> Accuracy: 0.7452836892031123, F-Score: 0.6086315789473685, Precision: 0.3091317365269461, Recall: 0.8031671065425754\n",
      "Min split loss 6 --> Accuracy: 0.7459587167371301, F-Score: 0.610313315926893, Precision: 0.310066324347454, Recall: 0.8052507292679539\n",
      "Min split loss 7 --> Accuracy: 0.7435428287206451, F-Score: 0.6092057761732851, Precision: 0.3079902376910017, Recall: 0.8063619947214891\n",
      "Min split loss 8 --> Accuracy: 0.7410203574093154, F-Score: 0.6105586428780344, Precision: 0.3065023597273204, Recall: 0.8119183219891651\n",
      "Min split loss 9 --> Accuracy: 0.7399189966959179, F-Score: 0.6098476945545587, Precision: 0.3055294240618794, Recall: 0.8120572301708571\n",
      "Min split loss 10 --> Accuracy: 0.7391196219845809, F-Score: 0.6084871233448024, Precision: 0.30460880004175583, Recall: 0.8106681483539381\n",
      "Min split loss 11 --> Accuracy: 0.7387110526876755, F-Score: 0.6096138626234016, Precision: 0.30461026121344575, Recall: 0.8131684956243923\n",
      "Min split loss 12 --> Accuracy: 0.740629551994884, F-Score: 0.6113035855908504, Precision: 0.3064128046866827, Recall: 0.8137241283511599\n",
      "Min split loss 13 --> Accuracy: 0.7393683163392191, F-Score: 0.6111076391058892, Precision: 0.30546155047638884, Recall: 0.814974301986387\n",
      "Min split loss 14 --> Accuracy: 0.7383024833907699, F-Score: 0.6117590802303583, Precision: 0.30487488991348494, Recall: 0.8174746492568412\n",
      "Min split loss 15 --> Accuracy: 0.7375919280918037, F-Score: 0.6106227791284833, Precision: 0.3040823718114555, Recall: 0.816363383803306\n",
      "Min split loss 16 --> Accuracy: 0.7359398870217074, F-Score: 0.6106205695808979, Precision: 0.3029305912596401, Recall: 0.8184470065286845\n",
      "Min split loss 17 --> Accuracy: 0.7371833587948982, F-Score: 0.6110372892616892, Precision: 0.30390334572490707, Recall: 0.8176135574385331\n",
      "Min split loss 18 --> Accuracy: 0.7361885813763456, F-Score: 0.6104060387375057, Precision: 0.30304746216410994, Recall: 0.8177524656202251\n",
      "Min split loss 19 --> Accuracy: 0.7370590116175791, F-Score: 0.6122025600066386, Precision: 0.3041170711598908, Recall: 0.8198360883456035\n",
      "Min split loss 20 --> Accuracy: 0.7366504423206736, F-Score: 0.6112056090275473, Precision: 0.3035751081805069, Recall: 0.8185859147103764\n",
      "Min split loss 21 --> Accuracy: 0.7356734287845952, F-Score: 0.6106656721983964, Precision: 0.3027579477171178, Recall: 0.8188637310737602\n",
      "Min split loss 22 --> Accuracy: 0.7361530536113973, F-Score: 0.6121814791796146, Precision: 0.30348156516380814, Recall: 0.8209473537991387\n",
      "Min split loss 23 --> Accuracy: 0.7339858599495506, F-Score: 0.6104819376704967, Precision: 0.30155165373621884, Recall: 0.820669537435755\n",
      "Min split loss 24 --> Accuracy: 0.7343944292464561, F-Score: 0.6099906919019547, Precision: 0.3017034119392296, Recall: 0.819280455618836\n",
      "Min split loss 25 --> Accuracy: 0.7359931786691299, F-Score: 0.6110500901498352, Precision: 0.30307858354319783, Recall: 0.8191415474371441\n",
      "Min split loss 26 --> Accuracy: 0.735069456780474, F-Score: 0.6116432546496473, Precision: 0.3025945448032342, Recall: 0.8213640783442144\n",
      "Min split loss 27 --> Accuracy: 0.7366504423206736, F-Score: 0.6117539712164572, Precision: 0.30371666838258005, Recall: 0.8195582719822198\n",
      "Min split loss 28 --> Accuracy: 0.7353714427825345, F-Score: 0.6117021276595744, Precision: 0.30281762295081965, Recall: 0.8210862619808307\n",
      "Min split loss 29 --> Accuracy: 0.7364017479660354, F-Score: 0.6128283749067707, Precision: 0.30382087099424815, Recall: 0.8217808028892902\n",
      "Min split loss 30 --> Accuracy: 0.7359398870217074, F-Score: 0.6113252113376431, Precision: 0.3031128004931169, Recall: 0.8196971801639117\n",
      "Min split loss 31 --> Accuracy: 0.7353003872526379, F-Score: 0.6116514900662252, Precision: 0.3027555828723622, Recall: 0.8210862619808307\n",
      "Min split loss 32 --> Accuracy: 0.7343589014815078, F-Score: 0.6108251152597737, Precision: 0.301895468247075, Recall: 0.8208084456174468\n",
      "Min split loss 33 --> Accuracy: 0.735424734429957, F-Score: 0.6113491915616006, Precision: 0.3027631106782181, Recall: 0.8203917210723711\n",
      "Min split loss 34 --> Accuracy: 0.7344299570114045, F-Score: 0.6104067999917275, Precision: 0.3018356598660326, Recall: 0.8199749965272954\n",
      "Min split loss 35 --> Accuracy: 0.7350516928979998, F-Score: 0.6117868520127426, Precision: 0.3026194617824619, Recall: 0.8216418947075983\n",
      "Min split loss 36 --> Accuracy: 0.7345898319536718, F-Score: 0.6106767601555391, Precision: 0.3020151391162029, Recall: 0.8202528128906793\n",
      "Min split loss 37 --> Accuracy: 0.7342167904217146, F-Score: 0.6107241044297911, Precision: 0.30177212604054954, Recall: 0.8208084456174468\n",
      "Min split loss 38 --> Accuracy: 0.7347674707784133, F-Score: 0.6110375641237795, Precision: 0.3022304072027829, Recall: 0.820669537435755\n",
      "Min split loss 39 --> Accuracy: 0.734731943013465, F-Score: 0.6118714852795235, Precision: 0.3024218270999387, Recall: 0.8221975274343659\n",
      "Min split loss 40 --> Accuracy: 0.7342345543041887, F-Score: 0.6112833230006199, Precision: 0.3019291619883638, Recall: 0.8217808028892902\n",
      "Min split loss 41 --> Accuracy: 0.7343411375990336, F-Score: 0.6108905978665342, Precision: 0.30190028606456887, Recall: 0.8209473537991387\n",
      "Min split loss 42 --> Accuracy: 0.7342345543041887, F-Score: 0.6108148331886394, Precision: 0.30180778265754266, Recall: 0.8209473537991387\n",
      "Min split loss 43 --> Accuracy: 0.7352115678402672, F-Score: 0.6111191604744064, Precision: 0.3025567454014449, Recall: 0.8202528128906793\n",
      "Min split loss 44 --> Accuracy: 0.7350516928979998, F-Score: 0.6111616934983237, Precision: 0.30245775729646696, Recall: 0.8205306292540631\n",
      "Min split loss 45 --> Accuracy: 0.7353892066650087, F-Score: 0.6092101718099107, Precision: 0.30218452839886917, Recall: 0.8166412001666898\n",
      "Min split loss 46 --> Accuracy: 0.7332753046505844, F-Score: 0.60974350501838, Precision: 0.30087638846428205, Recall: 0.8202528128906793\n",
      "Min split loss 47 --> Accuracy: 0.7336661100650158, F-Score: 0.6129837445333773, Precision: 0.3019817073170732, Recall: 0.8255313237949715\n",
      "Min split loss 48 --> Accuracy: 0.7340213877144989, F-Score: 0.6107414448669202, Precision: 0.30164319248826293, Recall: 0.8210862619808307\n",
      "Min split loss 49 --> Accuracy: 0.7343411375990336, F-Score: 0.6094053875118964, Precision: 0.3015149964172382, Recall: 0.8183080983469926\n",
      "Best min_split_loss: 47 with f2-score 0.6129837445333773\n"
     ]
    }
   ],
   "source": [
    "min_split_loss_parameters = range(0,50)\n",
    "best_param = [0,0]\n",
    "for param in min_split_loss_parameters:\n",
    "    estimator = XGBClassifier(min_child_weight=10, eta=0.2, gamma=param)\n",
    "    accuracy, f_score, precision, recall = validate_xgboost_classifier(estimator)\n",
    "    if f_score > best_param[0]:\n",
    "        best_param[0] = f_score\n",
    "        best_param[1] = param\n",
    "    print(f\"Min split loss {param} --> Accuracy: {accuracy}, F-Score: {f_score}, Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "print(f\"Best min_split_loss: {best_param[1]} with f2-score {best_param[0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth 1 --> Accuracy: 0.7418374960031264, F-Score: 0.6047253346762349, Precision: 0.30558795461774996, Recall: 0.8006667592721212\n",
      "Max depth 2 --> Accuracy: 0.7392972608093225, F-Score: 0.6092450115719023, Precision: 0.30493086355335247, Recall: 0.8117794138074733\n",
      "Max depth 3 --> Accuracy: 0.7336483461825417, F-Score: 0.6085230444761491, Precision: 0.30081259263044924, Recall: 0.8176135574385331\n",
      "Max depth 4 --> Accuracy: 0.7348740540732582, F-Score: 0.6105661782964986, Precision: 0.302181482998771, Recall: 0.8196971801639117\n",
      "Max depth 5 --> Accuracy: 0.7334174157103777, F-Score: 0.6100004130695197, Precision: 0.3010396493731526, Recall: 0.8205306292540631\n",
      "Max depth 6 --> Accuracy: 0.7336661100650158, F-Score: 0.6129837445333773, Precision: 0.3019817073170732, Recall: 0.8255313237949715\n",
      "Max depth 7 --> Accuracy: 0.7337549294773866, F-Score: 0.6093804907290654, Precision: 0.3011082171492774, Recall: 0.8190026392554521\n",
      "Max depth 8 --> Accuracy: 0.7320318328773937, F-Score: 0.6085512746473065, Precision: 0.29972572125152375, Recall: 0.8196971801639117\n",
      "Max depth 9 --> Accuracy: 0.7352648594876896, F-Score: 0.6100617207240793, Precision: 0.30231961408190494, Recall: 0.8183080983469926\n",
      "Max depth 10 --> Accuracy: 0.7330621380608946, F-Score: 0.6082644628099173, Precision: 0.30034686798612525, Recall: 0.8178913738019169\n",
      "Max depth 11 --> Accuracy: 0.7333641240629551, F-Score: 0.6093378783183556, Precision: 0.30083125095619356, Recall: 0.8194193638005278\n",
      "Max depth 12 --> Accuracy: 0.7329555547660497, F-Score: 0.608892284817446, Precision: 0.3004381495822295, Recall: 0.8191415474371441\n",
      "Max depth 13 --> Accuracy: 0.7329555547660497, F-Score: 0.608892284817446, Precision: 0.3004381495822295, Recall: 0.8191415474371441\n",
      "Max depth 14 --> Accuracy: 0.7329555547660497, F-Score: 0.608892284817446, Precision: 0.3004381495822295, Recall: 0.8191415474371441\n",
      "Max depth 15 --> Accuracy: 0.7329555547660497, F-Score: 0.608892284817446, Precision: 0.3004381495822295, Recall: 0.8191415474371441\n",
      "Max depth 16 --> Accuracy: 0.7329555547660497, F-Score: 0.608892284817446, Precision: 0.3004381495822295, Recall: 0.8191415474371441\n",
      "Max depth 17 --> Accuracy: 0.7329555547660497, F-Score: 0.608892284817446, Precision: 0.3004381495822295, Recall: 0.8191415474371441\n",
      "Max depth 18 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 19 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 20 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 21 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 22 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 23 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 24 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 25 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 26 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 27 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 28 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 29 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 30 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 31 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 32 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 33 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 34 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 35 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 36 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 37 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 38 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 39 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 40 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 41 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 42 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 43 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 44 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 45 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 46 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 47 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 48 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth 49 --> Accuracy: 0.7332220130031619, F-Score: 0.6087684138757464, Precision: 0.30058658505483293, Recall: 0.8185859147103764\n",
      "Max depth: 6 with f2-score 0.6129837445333773\n"
     ]
    }
   ],
   "source": [
    "max_depth_parameters = range(1,50)\n",
    "best_param = [0,0]\n",
    "for param in max_depth_parameters:\n",
    "    estimator = XGBClassifier(min_child_weight=10, eta=0.2, gamma=47, max_depth=param)\n",
    "    accuracy, f_score, precision, recall = validate_xgboost_classifier(estimator)\n",
    "    if f_score > best_param[0]:\n",
    "        best_param[0] = f_score\n",
    "        best_param[1] = param\n",
    "    print(f\"Max depth {param} --> Accuracy: {accuracy}, F-Score: {f_score}, Precision: {precision}, Recall: {recall}\")\n",
    "\n",
    "print(f\"Max depth: {best_param[1]} with f2-score {best_param[0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model with undersampling --> Accuracy: 0.7319252495825488, F-Score: 0.6079296971697336, Precision: 0.2994918699186992, Recall: 0.8187248228920684\n"
     ]
    }
   ],
   "source": [
    "data_train, data_validation, data_test, target_train, target_validation, target_test = get_preprocessed_brfss_dataset_label_encoded_train_test_split_undersampled(include_test_data=True)\n",
    "estimator = XGBClassifier(min_child_weight=10, eta=0.2, gamma=47, max_depth=6)\n",
    "estimator.fit(data_train, target_train)\n",
    "predictions = estimator.predict(data_validation)\n",
    "accuracy, f_score, precision, recall = accuracy_score(target_validation, predictions), fbeta_score(target_validation, predictions, beta=2), precision_score(target_validation, predictions), recall_score(target_validation, predictions)\n",
    "print(f\"Best model with undersampling --> Accuracy: {accuracy}, F-Score: {f_score}, Precision: {precision}, Recall: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model with oversampling --> Accuracy: 0.7353892066650087, F-Score: 0.6107763351349114, Precision: 0.302590407796871, Recall: 0.8194193638005278\n"
     ]
    }
   ],
   "source": [
    "data_train, data_validation, data_test, target_train, target_validation, target_test = get_preprocessed_brfss_dataset_label_encoded_train_test_split_oversampled(include_test_data=True)\n",
    "estimator = XGBClassifier(min_child_weight=10, eta=0.2, gamma=47, max_depth=6)\n",
    "estimator.fit(data_train, target_train)\n",
    "predictions = estimator.predict(data_validation)\n",
    "accuracy, f_score, precision, recall = accuracy_score(target_validation, predictions), fbeta_score(target_validation, predictions, beta=2), precision_score(target_validation, predictions), recall_score(target_validation, predictions)\n",
    "print(f\"Best model with oversampling --> Accuracy: {accuracy}, F-Score: {f_score}, Precision: {precision}, Recall: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on test data --> Accuracy: 0.7344169109157119, F-Score: 0.6086731525564065, Precision: 0.30137337296300093, Recall: 0.8169190165300736\n"
     ]
    }
   ],
   "source": [
    "data_train, data_validation, data_test, target_train, target_validation, target_test = get_preprocessed_brfss_dataset_label_encoded_train_test_split(include_test_data=True)\n",
    "\n",
    "estimator = XGBClassifier(min_child_weight=10, eta=0.2, gamma=47, max_depth=6)\n",
    "estimator.fit(data_train, target_train, sample_weight=sample_weights)\n",
    "predictions = estimator.predict(data_test)\n",
    "\n",
    "accuracy, f_score, precision, recall = accuracy_score(target_test, predictions), fbeta_score(target_test, predictions, beta=2), precision_score(target_test, predictions), recall_score(target_test, predictions)\n",
    "print(f\"Model performance on test data --> Accuracy: {accuracy}, F-Score: {f_score}, Precision: {precision}, Recall: {recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}