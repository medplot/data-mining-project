{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# K-nearest centroids\n",
    "In this notebook we want to train a K-nearest-centroid classifier that should predict whether a patient has diabetes or not."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I516258/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from preprocessing.preprocessing import *\n",
    "from preprocessing.preprocessing_label_encoding import *\n",
    "from preprocessing.preprocessing_one_hot_encoding import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#used to store the results and compare at the end\n",
    "approach_list = []\n",
    "acc_list = []\n",
    "cr_list = []\n",
    "f1_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter tuning and preprocessing\n",
    "We will evaluate different parameters for the classifier (hyperparameter tuning) as well as different preprocessing steps.\n",
    "\n",
    "In detail, we will vary regarding parameters:<br>\n",
    "\n",
    "\n",
    "| **Parameter** |                   **range Values**                    |\n",
    "|:-------------:|:-----------------------------------------------------:|\n",
    "| metric        | 'euclidean',<br>'cosine',<br>'manhattan',<br>'jaccard' |\n",
    "\n",
    "\n",
    "And we will vary for preprocessing:\n",
    "\n",
    "|              **Preprocessing**              |                           **Description**                           |\n",
    "|:-------------------------------------------:|:-------------------------------------------------------------------:|\n",
    "|               Label Encoding                |                           Label encoding                            |\n",
    "|     Label Encoding<br>+<br>Oversampling     |                   Label encoding and oversampling                   |\n",
    "|    Label Encoding<br>+<br>Undersampling     |                  Label encoding and undersampling                   |\n",
    "|            One Hot Encoding (1)             |           One hot encoding for all columns except yes/no            |\n",
    "|            One Hot Encoding (2)             |          One hot encoding for all columns including yes/no          |\n",
    "|  One Hot Encoding (1)<br>+<br>Oversampling  |   One hot encoding for all columns except yes/no and oversampling   |\n",
    "| One Hot Encoding (2) <br>+<br>Oversampling  | One hot encoding for all columns including yes/no and oversampling  |\n",
    "| One Hot Encoding (1)<br>+<br>Undersampling  |  One hot encoding for all columns except yes/no and undersampling   |\n",
    "| One Hot Encoding (2) <br>+<br>Undersampling | One hot encoding for all columns including yes/no and undersampling |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below defined function is used to store all the accuracy and f1-scores for a better comparison and evaluation capability at the end. It also returns the Accuracy score and F1-Score to see the performance directly under each method.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluation(target_validation, diabetes_test_prediction, metric, preproccessing):\n",
    "    approach = \"preprocessing: {} metric: {}\".format(preproccessing, metric)\n",
    "    approach_list.append(approach)\n",
    "    acc = accuracy_score(target_validation, diabetes_test_prediction)\n",
    "    acc_list.append(acc)\n",
    "    cr = classification_report(target_validation, diabetes_test_prediction)\n",
    "    cr_list.append(cr)\n",
    "    f1 = f1_score(target_validation, diabetes_test_prediction)\n",
    "    f1_list.append(f1)\n",
    "    return \"{}:\\n acc = {}\\n f1-score = {}\".format(approach, acc, f1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start with applying a K-nearest centroid classifier to the train data and test against the validation data on how it performs by using the accuracy and f1 score.\n",
    "\n",
    "We will do so for each combination that is listed above by using a for loop. The following estimators are structured by the different style of preprocessing.\n",
    "\n",
    "At the end we test the best approach against the actual test data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Label Encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = \"Label Encoding\"\n",
    "\n",
    "#load data\n",
    "data_train, data_validation, target_train, target_validation = get_preprocessed_brfss_dataset_label_encoded_train_test_split()\n",
    "\n",
    "#metrics that should be used\n",
    "params = ('euclidean', 'cosine', 'manhattan', 'jaccard')\n",
    "\n",
    "for metric in params:\n",
    "    nearest_centroid = NearestCentroid(metric=metric)\n",
    "    nearest_centroid.fit(data_train, target_train.values.ravel())\n",
    "    diabetes_test_prediction = nearest_centroid.predict(data_validation)\n",
    "    print(evaluation(target_validation, diabetes_test_prediction, metric, preprocessing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Label Encoding + Oversampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = \"Label Encoding + Oversampling\"\n",
    "\n",
    "#load data\n",
    "data_train, data_validation, target_train, target_validation = get_preprocessed_brfss_dataset_label_encoded_train_test_split_oversampled()\n",
    "\n",
    "#metrics that should be used\n",
    "params = ('euclidean', 'cosine', 'manhattan', 'jaccard')\n",
    "\n",
    "for metric in params:\n",
    "    nearest_centroid = NearestCentroid(metric=metric)\n",
    "    nearest_centroid.fit(data_train, target_train.values.ravel())\n",
    "    diabetes_test_prediction = nearest_centroid.predict(data_validation)\n",
    "    print(evaluation(target_validation, diabetes_test_prediction, metric, preprocessing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Label Encoding + Undersampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = \"Label Encoding + Undersampling\"\n",
    "\n",
    "#load data\n",
    "data_train, data_validation, target_train, target_validation = get_preprocessed_brfss_dataset_label_encoded_train_test_split_undersampled()\n",
    "\n",
    "#metrics that should be used\n",
    "params = ('euclidean', 'cosine', 'manhattan', 'jaccard')\n",
    "\n",
    "for metric in params:\n",
    "    nearest_centroid = NearestCentroid(metric=metric)\n",
    "    nearest_centroid.fit(data_train, target_train.values.ravel())\n",
    "    diabetes_test_prediction = nearest_centroid.predict(data_validation)\n",
    "    print(evaluation(target_validation, diabetes_test_prediction, metric, preprocessing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One Hot Encoding (1)\n",
    "yes/no values not one hot encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = \"One Hot Encoding (1)\"\n",
    "\n",
    "#load data\n",
    "data_train, data_validation, target_train, target_validation = get_preprocessed_brfss_dataset_one_hot_encoded()\n",
    "\n",
    "#metrics that should be used\n",
    "params = ('euclidean', 'cosine', 'manhattan', 'jaccard')\n",
    "\n",
    "for metric in params:\n",
    "    nearest_centroid = NearestCentroid(metric=metric)\n",
    "    nearest_centroid.fit(data_train, target_train.values.ravel())\n",
    "    diabetes_test_prediction = nearest_centroid.predict(data_validation)\n",
    "    print(evaluation(target_validation, diabetes_test_prediction, metric, preprocessing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One Hot Encoding (2)\n",
    "all columns one hot encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = \"One Hot Encoding (2)\"\n",
    "\n",
    "#load data\n",
    "data_train, data_validation, target_train, target_validation = get_preprocessed_brfss_dataset_one_hot_encoded_all_columns()\n",
    "\n",
    "#metrics that should be used\n",
    "params = ('euclidean', 'cosine', 'manhattan', 'jaccard')\n",
    "\n",
    "for metric in params:\n",
    "    nearest_centroid = NearestCentroid(metric=metric)\n",
    "    nearest_centroid.fit(data_train, target_train.values.ravel())\n",
    "    diabetes_test_prediction = nearest_centroid.predict(data_validation)\n",
    "    print(evaluation(target_validation, diabetes_test_prediction, metric, preprocessing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One Hot Encoding (1) + Oversampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = \"One Hot Encoding (1) + Oversampling\"\n",
    "\n",
    "#load data\n",
    "data_train, data_validation, target_train, target_validation = get_preprocessed_brfss_dataset_one_hot_encoded_train_test_split_oversampled()\n",
    "\n",
    "#metrics that should be used\n",
    "params = ('euclidean', 'cosine', 'manhattan', 'jaccard')\n",
    "\n",
    "for metric in params:\n",
    "    nearest_centroid = NearestCentroid(metric=metric)\n",
    "    nearest_centroid.fit(data_train, target_train.values.ravel())\n",
    "    diabetes_test_prediction = nearest_centroid.predict(data_validation)\n",
    "    print(evaluation(target_validation, diabetes_test_prediction, metric, preprocessing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One Hot Encoding (2) + Oversampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = \"One Hot Encoding (2) + Oversampling\"\n",
    "\n",
    "#load data\n",
    "data_train, data_validation, target_train, target_validation = get_preprocessed_brfss_dataset_one_hot_encoded_all_columns_train_test_split_oversampled()\n",
    "\n",
    "#metrics that should be used\n",
    "params = ('euclidean', 'cosine', 'manhattan', 'jaccard')\n",
    "\n",
    "for metric in params:\n",
    "    nearest_centroid = NearestCentroid(metric=metric)\n",
    "    nearest_centroid.fit(data_train, target_train.values.ravel())\n",
    "    diabetes_test_prediction = nearest_centroid.predict(data_validation)\n",
    "    print(evaluation(target_validation, diabetes_test_prediction, metric, preprocessing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One Hot Encoding (1) + Undersampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = \"One Hot Encoding (1) + Undersampling\"\n",
    "\n",
    "#load data\n",
    "data_train, data_validation, target_train, target_validation = get_preprocessed_brfss_dataset_one_hot_encoded_train_test_split_undersampled()\n",
    "\n",
    "#metrics that should be used\n",
    "params = ('euclidean', 'cosine', 'manhattan', 'jaccard')\n",
    "\n",
    "for metric in params:\n",
    "    nearest_centroid = NearestCentroid(metric=metric)\n",
    "    nearest_centroid.fit(data_train, target_train.values.ravel())\n",
    "    diabetes_test_prediction = nearest_centroid.predict(data_validation)\n",
    "    print(evaluation(target_validation, diabetes_test_prediction, metric, preprocessing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One Hot Encoding (2) + Undersampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preprocessing = \"One Hot Encoding (2) + Undersampling\"\n",
    "\n",
    "#load data\n",
    "data_train, data_validation, target_train, target_validation = get_preprocessed_brfss_dataset_one_hot_encoded_all_columns_train_test_split_undersampled()\n",
    "\n",
    "#metrics that should be used\n",
    "params = ('euclidean', 'cosine', 'manhattan', 'jaccard')\n",
    "\n",
    "for metric in params:\n",
    "    nearest_centroid = NearestCentroid(metric=metric)\n",
    "    nearest_centroid.fit(data_train, target_train.values.ravel())\n",
    "    diabetes_test_prediction = nearest_centroid.predict(data_validation)\n",
    "    print(evaluation(target_validation, diabetes_test_prediction, metric, preprocessing))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation of best approach\n",
    "We use the following loop to print all F1- and accuracy-scores and thereby also analyze which approach performed best."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "highest_acc = [0.0, None, None]\n",
    "highest_f1 = [0.0, None, None]\n",
    "\n",
    "for i in range(0, len(approach_list)):\n",
    "    print(\"Nr.{}) {}\".format(i, approach_list[i]))\n",
    "    print (\"Weighted F1-Score = {}\".format(f1_list[i]))\n",
    "    print (\"Accuracy-Score = {}\\n\".format(acc_list[i]))\n",
    "    if highest_f1[0] < float(f1_list[i]):\n",
    "        highest_f1[0] = f1_list[i]\n",
    "        highest_f1[1] = i\n",
    "        highest_f1[2] = approach_list[i]\n",
    "    if highest_acc[0] < float(acc_list[i]):\n",
    "        highest_acc[0] = acc_list[i]\n",
    "        highest_acc[1] = i\n",
    "        highest_acc[2] = approach_list[i]\n",
    "\n",
    "print(\"--------- Best Approaches ---------\")\n",
    "print(\"Best Approach regarding F1-Score:\\nNr.{}) {} with f1-score = {}\\n\".format(highest_f1[1], highest_f1[2], highest_f1[0]))\n",
    "print(\"Best Approach regarding Accuracy:\\nNr.{}) {} with acc = {}\".format(highest_acc[1], highest_acc[2], highest_acc[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that approach _tbd_ with k = _tbd_ and metric = _tbd_ performed best.\n",
    "We test this approach now finally against the test data that we separated at the beginning:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#tbd"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
